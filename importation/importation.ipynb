{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connexion à la base de données brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect = sqlite3.connect(\"../Databases/raw-database.db\")\n",
    "cursor = connect.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données de matching des matchs Skill Corner / Stats Bomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de l'unique fichier pour ces données\n",
    "matching_matches = pd.read_json(\"Projet_centres_data/matching_matches.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id_SB</th>\n",
       "      <th>match_id_SKC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3894366.0</td>\n",
       "      <td>1547880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3894367.0</td>\n",
       "      <td>1547881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   match_id_SB  match_id_SKC\n",
       "0    3894366.0       1547880\n",
       "1    3894367.0       1547881"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_matches.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons renommer les colonnes de ce dataframe pour leur donné un nom plus cohérent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire permettant de renommer les colonnes souhaitées\n",
    "dico_rename = {\"statsbomb_id\" : \"match_id_SB\", \"skillcorner_id\" : \"match_id_SKC\"}\n",
    "matching_matches.rename(dico_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "matching_matches.to_sql(\"matching_matches\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données de matching des joueurs Skill Corner / Stats Bomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de l'unique fichier pour ces données\n",
    "matching_players = pd.read_json(\"Projet_centres_data/matching_players.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birthday</th>\n",
       "      <th>trackable_object</th>\n",
       "      <th>gender</th>\n",
       "      <th>statsbomb_id</th>\n",
       "      <th>skillcorner_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-05</td>\n",
       "      <td>820104</td>\n",
       "      <td>male</td>\n",
       "      <td>307251.0</td>\n",
       "      <td>818541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-28</td>\n",
       "      <td>39010</td>\n",
       "      <td>male</td>\n",
       "      <td>66886.0</td>\n",
       "      <td>37889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     birthday  trackable_object gender  statsbomb_id  skillcorner_id\n",
       "0  2006-04-05            820104   male      307251.0          818541\n",
       "1  1997-11-28             39010   male       66886.0           37889"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_players.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons renommer les colonnes de ce dataframe pour leur donné un nom plus cohérent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire permettant de renommer les colonnes souhaitées\n",
    "dico_rename = {\"statsbomb_id\" : \"player_id_SB\", \"skillcorner_id\" : \"player_id_SKC\"}\n",
    "matching_players.rename(dico_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "matching_players.to_sql(\"matching_players\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données de matching des équipes Skill Corner / Stats Bomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de l'unique fichier pour ces données\n",
    "matching_teams = pd.read_json(\"Projet_centres_data/matching_teams.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsbomb_id</th>\n",
       "      <th>skillcorner_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statsbomb_id  skillcorner_id\n",
       "0           168              85\n",
       "1           144              66"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_teams.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons renommer les colonnes de ce dataframe pour leur donné un nom plus cohérent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire permettant de renommer les colonnes souhaitées\n",
    "dico_rename = {\"statsbomb_id\" : \"team_id_SB\", \"skillcorner_id\" : \"team_id_SKC\"}\n",
    "matching_teams.rename(dico_rename, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "matching_teams.to_sql(\"matching_teams\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informations sur les matchs Stats Bomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture de l'unique fichier pour ces données\n",
    "SB_matches = pd.read_json(\"Projet_centres_data/data_add/SB_matches_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "SB_matches.to_sql(\"SB_matches\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données events de Stats Bomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ces données, nous avons un fichier par match, il faut donc importer une liste de fichiers (situés dans le dossier SB_events).  \n",
    "Pour ce faire, nous allons ouvrir un par un ces fichiers et les concaténer afin d'obtenir un unique jeu de données comprenant l'ensemble des fichiers.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des fichiers à ouvrir\n",
    "liste_fichier_events = os.listdir(\"Projet_centres_data/SB_events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commande qui permet de concaténer l'ensemble des fichiers\n",
    "# La boucle for à l'intérieur des [] permet de parcourir la liste des noms des fichiers, et d'ouvrir un fichier un chaque itération\n",
    "events = pd.concat([pd.read_json(\"Projet_centres_data/SB_events/\" + fichier_event) for fichier_event in liste_fichier_events])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant filtrer ces données afin de :  \n",
    "- Garder uniquement les données dont nous nous servirons. En effet, ces données contiennent 108 variables(colonnes) de base, or elles ne nous sont pas toutes utiles, nous allons donc garder seulement celles qui nous sont utiles afin de réduire la taille des données.  \n",
    "- Renommer certaines colonnes afin de faciliter notre utilisation de ces dernières.  \n",
    "- Convertir les colonnes contenant des données stockées sous forme de liste en plusieurs colonnes comprenant chacune un élément de la liste.  \n",
    "En effet, les bases de données SQLite ne supportent pas les données de type liste, dictionnaire, dataframe etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste contenant les noms de colonnes que nous souhaitons garder\n",
    "colonnes = [\"id\", \"shot_type\", \"shot_outcome\", \"type\", \"match_id\", \"period\", \"possession\", \"location\", \"pass_cross\", \"pass_type\", \"index\",\n",
    "            \"pass_end_location\", \"minute\", \"shot_end_location\", \"pass_body_part\", \"player_id\"]\n",
    "# Commande pour garder uniquement colonnes souhaitées\n",
    "events = events[colonnes]\n",
    "\n",
    "# Renommage des colonnes\n",
    "# Dictionnaire permettant de renommer les colonnes souhaitées\n",
    "dico_rename = {\"index\" : \"index_event\", \"id\" : \"event_id\", \"match_id\" : \"match_id_SB\"}\n",
    "events.rename(dico_rename, axis = 1, inplace = True)\n",
    "\n",
    "# La colonne \"index_event\" va nous permettre, pour chaque match, de trier les events par ordre chronologique\n",
    "events.sort_values(by = [\"match_id_SB\", \"index_event\"], inplace = True)\n",
    "\n",
    "# De plus, nous utilisons la commande reset_index afin d'obtenir un unique identifiant pour chaque evenement de l'ensemble des données concaténées.\n",
    "# En effet, les index du dataframe actuel ne sont pas uniques car on a effectué une concaténantion de plusieurs dataframes qui avaient des\n",
    "# index en communs.\n",
    "events.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Les données de la colonne \"location\" sont des listes de 3 coordonnées, nous allons donc \"éclater\" cette colonne en 3 colonnes :\n",
    "# \"x_loc\", \"y_loc\" et \"z_loc\".\n",
    "# Pour ce faire, nous extrayons d'abord la colonne du dataframe, puis nous créons un autre dataframe comprenant les 3 colonnes des coordonnées\n",
    "events_loc = events.pop(\"location\").dropna()\n",
    "events_loc = pd.DataFrame(events_loc.tolist(), index = events_loc.index, columns = [\"x_loc\", \"y_loc\", \"z_loc\"])\n",
    "\n",
    "# De même pour la colonne \"pass_end_location\", sauf que celle-ci ne contient que 2 coordonnées\n",
    "events_pass_loc = events.pop(\"pass_end_location\").dropna()\n",
    "events_pass_loc = pd.DataFrame(events_pass_loc.tolist(), index = events_pass_loc.index, columns = [\"x_pass\", \"y_pass\"])\n",
    "\n",
    "# De même pour la colonne \"shot_end_location\" qui comprend 3 coordonnées\n",
    "events_shot_loc = events.pop(\"shot_end_location\").dropna()\n",
    "events_shot_loc = pd.DataFrame(events_shot_loc.tolist(), index = events_shot_loc.index, columns = [\"x_shot\", \"y_shot\", \"z_shot\"])\n",
    "\n",
    "# Il nous reste a concaténer les 3 dataframes créés précédemment avec le dataframe initial.\n",
    "# Nous concaténons ces dataframes horizontalement (nous les ajoutons à droite du dataframe initial)\n",
    "events = pd.concat([events, events_loc, events_pass_loc, events_shot_loc], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1118352"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "events.to_sql(\"events\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données freeze frame de Skill Corner sur les centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même que pour les données event, nous disposons de 1 fichier par match pour ces données, nous allons donc concaténer l'ensemble des données de chaque fichier dans un seul jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des fichiers à ouvrir\n",
    "liste_fichier_freeze_frames = os.listdir(\"Projet_centres_data/SKC_crosses_freeze_frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, cette fois nous souhaitons aussi conserver l'information \"match_id\" (Skill Corner) pour chaque match, qui n'est pas initialement pas présente dans les données \"freeze frames\".  \n",
    "Cette information est en fait stockée dans le nom des fichiers qui sont de la forme \"match_id.json\".  \n",
    "Pour ce faire, nous allons, grâce à une boucle for : \n",
    "- Parcourir la liste des noms des fichiers à lire (le nom correspond au \"match_id\" Skill Corner)\n",
    "- Lire le fichier correspondant\n",
    "- Ajouter l'information \"match_id_SKC\" dans une nouvelle colonne (le \"match_id\" sera ajouté à toutes les lignes du dataframe)\n",
    "- Concaténer le jeu de données (dataframe) obtenu lors de l'itération au jeu de données comprenant l'ensemble des données des fichier lus lors des précédentes itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dataframe qui contiendra le jeu de données concaténé (les données de l'ensemble des fichiers de données \"freeze frames\")\n",
    "freeze_frames = pd.DataFrame()\n",
    "\n",
    "# Boucle itérative\n",
    "for fichier_freeze_frames in liste_fichier_freeze_frames :\n",
    "    # Lecture du fichier correspondant\n",
    "    freeze_frames_import = pd.read_json(\"Projet_centres_data/SKC_crosses_freeze_frames/\" + fichier_freeze_frames)\n",
    "    \n",
    "    # Création de la colonne \"match_id_SKC\"\n",
    "    # Nous enlevons la partie \".json\" de la chaine de caractères correspondant au nom du fichier\n",
    "    freeze_frames_import[\"match_id_SKC\"] = int(fichier_freeze_frames.replace(\".json\", \"\"))\n",
    "\n",
    "    # Concaténation du dataframe obtenu au dataframe comprenenant le jeu de données\n",
    "    freeze_frames = pd.concat([freeze_frames, freeze_frames_import])\n",
    "\n",
    "# De même que pour les données events, nous allons trier les freeze frames par ordre chronologique pour chaque match\n",
    "freeze_frames.sort_values(by = [\"match_id_SKC\", \"timestamp\"], inplace = True)\n",
    "\n",
    "# Pour les mêmes raisons que pour les données events, nous allons créer un nouvel index pour identifier les freeze frames.\n",
    "freeze_frames.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Nous supprimons la variable \"image_corners_projection\" qui nous est inutile\n",
    "freeze_frames.drop(\"image_corners_projection\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut traiter la colonne \"possession\", qui contient des dictionnaires comprenant chacuns le joueur et l'équipe en possession du ballon au moment ou la frame a été capturée.  \n",
    "En effet, ces dictionnaires ne peuvent pas être stocké par SQLite...  \n",
    "Pour ce faire, nous allons procéder comme pour les listes de coordonnées précédentes :\n",
    "- Supprimer et récupérer la colonne du dataframe\n",
    "- Eclater cette colonne en 2 nouvelles colonnes qui contiennent respectivement l'équipe en possession du ballon et le joueur en possession du ballon lors de la frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_frames_possession = freeze_frames.pop(\"possession\")\n",
    "freeze_frames[[\"group\", \"tackable_object\"]] = pd.json_normalize(freeze_frames_possession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant traiter la colonne \"data\", qui contient pour chaque frame des informations (position, vitesse, etc) pour chaque joueur et le ballon.  \n",
    "En effet, pour chaque frame, la valeur de cette colonne est en fait une liste de dictionnaire.  \n",
    "Chaque dictionnaire de la liste correspond aux informations (position, vitesse, etc) pour un joueur ou le ballon.  \n",
    "De ce fait, les données de cette colonne \"data\" ne peuvent pas être stockées par SQLite.  \n",
    "Cependant, nous pouvons voir chaque élèment de cette colonne comme un dataframe, car ces élèments sont des listes de dictionnaires (possédant tous les même clés).  \n",
    "De ce fait, en convertissant chaque ligne de cette colonne en un dataframe, nous obtiendrons donc (nombre de frames) dataframes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer cette manipulation, nous allons utilisé la commande \"apply\" de Pandas. Lorsque le paramètre de la commande \"axis\" = 1, cette méthode permet d'appliquer une fonction (passée en paramètre) à chaque ligne du dataframe.  \n",
    "Grâce à cela, nous allons pouvoir, pour chaque frame, leur appliquer une fonction extrayant l'information \"data\" en la convertissant en dataframe, et ajouter à ce dataframe créé (pour chaque frame), l'information sur l'identifiant de la frame et le match id Skill Corner.  \n",
    "Cette fonction se nomme \"transform_freeze_frames_data\", et est définie dans la cellule ci-dessous.  \n",
    "La commande apply, appliquée au dataframe avec la fonction \"transform_freeze_frames_data\", renverra une série de tous les dataframes créés, concaténés les uns en dessous des autres.  \n",
    "Nous convertissons ensuite cette série de dataframe en liste de dataframe avec la commande \"tolist\", car chaque ligne de la série est en réalité un dataframe.  \n",
    "Et finalement, nous appliquerons la fonction \"concat\" afin de concaténer l'ensemble des dataframes de la liste créée, les uns en dessous des autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_freeze_frames_data(row) :\n",
    "    # Création du dataframe contenant l'information \"data\" pour la ligne itérée.\n",
    "    # Cette information \"data\" est donc une liste de dictionnaire, qui peut être convertie en dataframe\n",
    "    df = pd.DataFrame(row.data)\n",
    "    # Ajout de l'information sur l'id de la frame\n",
    "    df[\"frame\"] = row.frame\n",
    "    # Ajout de l'information sur le match id\n",
    "    df[\"match_id_SKC\"] = row.match_id_SKC\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_frames_data = pd.concat((freeze_frames.apply(transform_freeze_frames_data, axis = 1)).tolist())\n",
    "\n",
    "# Suppression de la colonne data du dataframe initial, contenant les freeze frames\n",
    "freeze_frames.drop(\"data\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20576"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "freeze_frames.to_sql(\"freeze_frames\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467914"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "freeze_frames_data.to_sql(\"freeze_frames_data\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données off ball runs de Skill Corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données off ball runs de Skill Corner sont également agrégées par match, nous avons donc un fichier par match.  \n",
    "Comme pour les freeze frames, le nom de ces fichiers est de la forme \"match_id.json\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des fichiers à ouvrir\n",
    "liste_fichier_off_ball_runs = os.listdir(\"Projet_centres_data/SKC_off_ball_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dataframe contenant les données de l'ensemble des matchs à disposition.\n",
    "# Comme précédemment, l'ensemble des données importées sont concaténées les unes en dessous des autres avec la commande \"concat\".\n",
    "off_ball_runs = pd.concat([pd.read_json(\"Projet_centres_data/SKC_off_ball_runs/\" + fichier_off_ball_runs)\n",
    "                           for fichier_off_ball_runs in liste_fichier_off_ball_runs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8489"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "off_ball_runs.to_sql(\"off_ball_runs\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données Lineup de Stats Bomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous allons importer les données lineup de Stats Bomb qui sont elles aussi agrégées par match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des fichiers à ouvrir\n",
    "liste_fichier_lineups = os.listdir(\"Projet_centres_data/SB_lineups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant, de même que pour les données freeze frames, nous ne disposons pas directement de l'information sur les match id Stats Bomb.  \n",
    "De ce fait, il est nécessaire, à chaque fois qu'on import les données lineup d'un match, d'ajouter une colonne contenant le match id à ces données.  \n",
    "Nous pourrons récupérer le match id correspondant au fichier importé car le match id est contenu dans le nom des fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne du dataframe : Index([147, 156], dtype='int64')\n",
      "Index du dataframe : Index(['team_id', 'lineup', 'formations', 'events'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "exemple_lineup = pd.read_json(\"Projet_centres_data/SB_lineups/3894037.json\")\n",
    "print(\"Colonne du dataframe :\", exemple_lineup.columns)\n",
    "print(\"Index du dataframe :\", exemple_lineup.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, comme nous pouvons le voir, les données de ces fichiers lineup sont \"inversées\" : les variables sont contenues dans les lignes et les individus (les team id) sont contenus dans les colonnes.  \n",
    "Cela n'est d'une part, pas cohérent, et d'autre part, posera posera problème lorsque nous vondront concaténer l'ensemble des fichiers importés.  \n",
    "Pour cela, il est nécessaire, à chaque importation de fichier, de \"transposer\" les dataframe résultant de l'importation du fichier.  \n",
    "Cela permettra de définir les team id en tant que lignes et les variables en tant que colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous ne garderons que les colonnes \"team_id\" et \"lineup\", car les autres informations ne nous sont pas utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dataframe qui contiendra l'ensemble des données, concaténées\n",
    "lineups = pd.DataFrame()\n",
    "\n",
    "# Boucle pour traverser l'ensemble des fichiers\n",
    "for fichier_lineups in liste_fichier_lineups :\n",
    "    # Lecture du fichier correspondant et transposition des colonnes/lignes\n",
    "    lineups_import = pd.read_json(\"Projet_centres_data/SB_lineups/\" + fichier_lineups).transpose()\n",
    "\n",
    "    # On ne garde que les colonnes \"team_id\" et \"lineup\"\n",
    "    lineups_import = lineups_import[[\"team_id\", \"lineup\"]]\n",
    "    \n",
    "    # Création de la colonne \"match_id_SB\"\n",
    "    # Nous enlevons la partie \".json\" de la chaine de caractères correspondant au nom du fichier\n",
    "    lineups_import[\"match_id_SB\"] = int(fichier_lineups.replace(\".json\", \"\"))\n",
    "\n",
    "    # Concaténation du dataframe obtenu au dataframe comprenenant le jeu de données\n",
    "    lineups = pd.concat([lineups, lineups_import])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'écrire ces données dans la BDD SQLite, il est important de modifier la colonne \"lineup\" qui contient, comme pour la colonne \"data\" des freeze frames, des listes de dictionnaire.  \n",
    "En effet, chaque liste de dictionnaire contient, pour une équipe et un match donnés, des informations sur l'ensemble des joueurs de cette équipe inscrits sur la feuille de match.  \n",
    "Nous pouvons donc, pour chaque ligne de la colonne lineup, convertir la liste de dictionnaire en dataframe et concaténer l'ensemble des dataframes résultants.  \n",
    "Nous allons encore une fois utiliser la commande apply de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_lineups(row) :\n",
    "    # Création du dataframe correspondant à la liste de dictionnaire de la colonne \"lineup\" de la ligne itérée.\n",
    "    # Dataframe qui contient donc dans les lignes, l'ensemble des joueurs d'une équipe inscrits sur la feuille de match\n",
    "    # et dans les colonnes, les informations sur ces joueurs\n",
    "    df = pd.DataFrame(row.lineup)\n",
    "    # Ajout de l'information \"team_id\"\n",
    "    df[\"team_id\"] = row.team_id\n",
    "    # Ajout de l'information sur les match id\n",
    "    df[\"match_id_SB\"] = row.match_id_SB\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On modifie le dataframe initial avec la commande apply, de la même façon que pour les freeze frames\n",
    "# Le dataframe résultant contiendra donc sur les lignes, les informations sur l'ensemble des joueurs de toutes les équipes, pour tous les matchs.\n",
    "# Il contiendra aussi les colonnes \"team_id\" et \"match_id_SB\" qui ont été ajoutées par la fonction \"transform_lineups\"\n",
    "lineups = pd.concat((lineups.apply(transform_lineups, axis = 1)).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>player_gender</th>\n",
       "      <th>player_height</th>\n",
       "      <th>player_weight</th>\n",
       "      <th>jersey_number</th>\n",
       "      <th>country</th>\n",
       "      <th>positions</th>\n",
       "      <th>stats</th>\n",
       "      <th>team_id</th>\n",
       "      <th>match_id_SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2941</td>\n",
       "      <td>1998-02-25</td>\n",
       "      <td>male</td>\n",
       "      <td>185.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>23</td>\n",
       "      <td>{'id': 202, 'name': 'Senegal'}</td>\n",
       "      <td>[{'position_id': 12, 'position': 'Right Midfie...</td>\n",
       "      <td>{'own_goals': 0, 'goals': 0, 'assists': 1, 'pe...</td>\n",
       "      <td>147</td>\n",
       "      <td>3894037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3044</td>\n",
       "      <td>1994-08-08</td>\n",
       "      <td>male</td>\n",
       "      <td>182.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>99</td>\n",
       "      <td>{'id': 52, 'name': 'Congo, (Kinshasa)'}</td>\n",
       "      <td>[{'position_id': 5, 'position': 'Left Center B...</td>\n",
       "      <td>{'own_goals': 0, 'goals': 0, 'assists': 0, 'pe...</td>\n",
       "      <td>147</td>\n",
       "      <td>3894037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player_id  birth_date player_gender  player_height  player_weight  \\\n",
       "0       2941  1998-02-25          male          185.0           76.0   \n",
       "1       3044  1994-08-08          male          182.0           81.0   \n",
       "\n",
       "   jersey_number                                  country  \\\n",
       "0             23           {'id': 202, 'name': 'Senegal'}   \n",
       "1             99  {'id': 52, 'name': 'Congo, (Kinshasa)'}   \n",
       "\n",
       "                                           positions  \\\n",
       "0  [{'position_id': 12, 'position': 'Right Midfie...   \n",
       "1  [{'position_id': 5, 'position': 'Left Center B...   \n",
       "\n",
       "                                               stats  team_id  match_id_SB  \n",
       "0  {'own_goals': 0, 'goals': 0, 'assists': 1, 'pe...      147      3894037  \n",
       "1  {'own_goals': 0, 'goals': 0, 'assists': 0, 'pe...      147      3894037  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineups.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce dataframe résultant contient également des colonnes composées de dictionnaire (\"country\", \"positions\" et \"stats\").  \n",
    "Cependant, ces informations ne nous sont pas utiles, nous avons donc juste à les supprimer du dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineups.drop([\"country\", \"positions\", \"stats\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12227"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ecriture des données importées dans une table de la BDD\n",
    "lineups.to_sql(\"lineups\", con = connect, if_exists = \"replace\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fermeture de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin de l'importation des données, nous fermons donc le connecteur à la base de données.\n",
    "connect.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_PROJET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
